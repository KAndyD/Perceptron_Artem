
# Лабораторная работа: Реализация и обучение перцептрона «Артем»

## Цель

Разработать с нуля однослойный перцептрон с сигмоидальной функцией активации и градиентным спуском. Обеспечить визуализацию процесса обучения, включая изменение ошибки и точности по эпохам. Проверить работу модели на синтетических данных.

---

## Используемые библиотеки

| Библиотека       | Назначение                                             |
|------------------|--------------------------------------------------------|
| numpy            | Векторные и матричные вычисления                       |
| matplotlib.pyplot| Визуализация ошибок и точности                         |
| sklearn.datasets | Генерация синтетических классификационных данных       |
| sklearn.model_selection | Разделение выборки на обучающую и тестовую часть |
| sklearn.preprocessing | Нормализация данных (стандартизация признаков)    |

---

## Алгоритм: Перцептрон с сигмоидой (модель «Артем»)

Модель реализована вручную. Отличительные особенности:

- Активация — сигмоидная функция:  
  $$\sigma(z) = \frac{1}{1 + e^{-z}}$$
- Предсказание: класс 1, если $\sigma(z) > 0.5$, иначе 0
- Функция потерь: среднеквадратичная ошибка (MSE)
- Обновление весов: градиентный спуск  
  $$w = w - \text{learning\_rate} \cdot \nabla \text{loss}$$

### Основные методы:

#### `__init__(self, input_size, learning_rate=0.1, epochs=1000)`

- Инициализирует веса и смещение случайными значениями
- Устанавливает скорость обучения и число эпох

#### `sigmoid(self, z)`

- Вычисляет сигмоиду от входа z

#### `sigmoid_derivative(self, z)`

- Вычисляет производную сигмоиды для градиентного спуска

#### `predict(self, x)`

- Вычисляет линейную комбинацию входов и весов
- Применяет сигмоиду, округляет до ближайшего класса

#### `train(self, X, d)`

- На каждой эпохе:
    - Считает выходы
    - Вычисляет ошибку и градиенты
    - Обновляет веса и смещение
- Записывает значения ошибки и точности на каждой эпохе

---

## Этапы работы

### 1. Генерация данных

С помощью `make_classification` создаётся 400 примеров с 2 признаками:

```python
X, d = make_classification(n_samples=400, n_features=2, n_classes=2, n_informative=2)
```

### 2. Нормализация

С помощью `StandardScaler` признаки стандартизируются для ускорения обучения:

```python
scaler = StandardScaler()
X = scaler.fit_transform(X)
```

### 3. Обучение модели

```python
model = Artem(input_size=2, learning_rate=0.1, epochs=1000)
model.train(X_train, y_train)
```

- learning_rate = 0.1
- epochs = 1000
- input_size = 2

### 4. Проверка качества

Модель тестируется на отложенной выборке, выводится точность:

```python
accuracy = model.evaluate(X_test, y_test)
print(f"Точность: {accuracy:.2f}")
```

---

## Визуализация

### Ошибка по эпохам

График среднеквадратичной ошибки (MSE) на обучающей выборке:

![Ошибка](error_plot.png)

### Точность по эпохам

Как модель улучшает свои предсказания во времени:

![Точность](accuracy_plot.png)

---

## Результаты

- Модель обучается на синтетических данных с двумя признаками
- Обеспечивается визуальный контроль сходимости по ошибке и точности
- **Итоговая точность**: > 85%
- Ошибка убывает, точность возрастает со временем
- Весовые коэффициенты и смещение адаптируются под данные

---

## Заключение

Перцептрон «Артем» успешно реализован с нуля. Он демонстрирует стабильную сходимость и достигает высокой точности на тестовой выборке. Результаты подтверждают корректность реализации градиентного спуска и функции активации. Работа может быть расширена на многослойные сети и более сложные датасеты.

---

## Сохранённые изображения

- `error_plot.png` — ошибка обучения
- `accuracy_plot.png` — точность по эпохам# Perceptron_Artem
